* Overview
This repository was created to host my Digital Image Processing course's final project. I've implemented a face-swap algorithm to be performed on real-time upon the frames captured by my laptop's camera.

* Algorithm - brief description
The face-swap effect is, in reality, the result of a series of techniques put together to achieve such outcome. I'll briefly discuss each one of them to allow for us to have a better understanding of the produced results.
** Facial landmarks detection
The first step in the face-swapping algorithm is to use a method of facial landmark detection. It is common to do so using the Haars classifiers, which can be promptly done using OpenCV's CascadeClassifier class. However, here I've used the face shape detector provided by the Dlib library. In order to use it, we need a file commonly found under the name of /shape_predictor_68_face_landmarks.dat/, which contains data regarding facial landmarks used to train our detector (which perform regression on this data to be able and find the landmarks on unkown images). In the picture below we can see an example of landmark detection. It is important to note, furthermore, that we don't use all of the points from the landmarks, as our itent is to extract only the contour of the source face (so we can << patch >> it on top of the destination face).

[[./figures/landmarks.png]]

** Finding the "Hull"
After obtaining the landmarks, we proceed to extract the "hull" (i.e.: the contour of the set of facil landmark points), as the points from the interior do not interest us at this second stage. In the previous figure, the hull would be a shape connecting all of the exterior red points, ignoring the interior ones. To calculate the hull of our landmark, we can use OpenCV's convexHull function as shown below:

#+begin_src cpp
  cv::convexHull(element, hull_index, false, false);
#+end_src

In the above snippet, *element* is a set of points representing the detected landmarks and *hull_index* is the index of the landmark points that form the hull (or the contour); the other two parameters simply control the behavior of the method: they tell if the detection is to be performed clockwise (not the case here) and if the latter flag is set to /true/, the hull points (instead of their indexes) are returned.

Once the hull for the destination face is obtained, we proceed to the Delaunay triangulation.

** Delaunay triangulation and affine transformation.

This process seems to be more complex than the previous, but it works in a simple manner: the hull region is subdivided into smaller zones, triangular zones, which allow the faces to be overlap better in the final figure. The smaller triangles inside the hull zone are defined for each to keep a small region of the face, containing one of its key features; this helps warp the source face when "patching" it onto the destination. After performing the triangulation, it is still needed to perform a affine transformation to align the triangles from the source face with those on the destination face. We could, of course, simply toss one on top of the other, but the result wouldn't be as smooth as the one obtained via this kind of transformation.

After finding the Delaunay triangles and performing the affine transformation, we obtain a mask as the one shown in the figure below; this mask, by its turn, is applied to the source image to mix it with the destination image.

[[./figures/mask.png]]

** Raw patching and seamless cloning

As mentioned above, we can simply "paste" the source face on the destination image; however, the results is not as good as we'd expect. To workaround this issue, we can use an OpenCV method that "smoothly" blends the two faces toghether: seamlessClone. Its usage in the code in as follows:

#+begin_src cpp
  cv::Mat output;
  cv::seamlessClone(copied_image, destination_image, mask, center, output, cv::NORMAL_CLONE);
  cv::imshow("blended", output);
#+end_src

In the above code, the first argument is the raw-copied image and the second is the destination frame (unaltered destination frame); the third one is the mask, shown in the preceeding sub-section: it's the responsible for making the smooth bleding between the two faces, and this blending will be output on the *output* image, centered around *center*. The last parameter controls the kind of cloning (for more info about this, please check the method's documentation). Then, the blended output is shown on screen.

The two figures below show, side by side, the result of a simple, raw-copying, and of a seamless cloning procedure: the results produced by the latter are much smoother (specially around the transition edges) than those produced by the former.

|---------------------------------------------+--------------------------------|
| Result of the simple face-copying procedure | Result of the seamless cloning |
|---------------------------------------------+--------------------------------|
| [[./figures/raw-copy.png]]                      | [[./figures/swap-final-2.png]]     |
|---------------------------------------------+--------------------------------|

** Final comments

The code was adapted from the algorithm I found at anishakd4's Github page, and from the algorithm at Learnopencv's "Face swap" repository. I modified those to fit my needs (e.g.: to apply the face swapping effect to a real-time captured frame containing two faces in it), and made a few modifications to make them more efficient in what concerns memory allocation - as I was no longer performing a single face swap, but several per minute.
