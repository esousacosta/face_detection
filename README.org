* Overview
This repository was created to host my Digital Image Processing course's final project. I've implemented a face-swap algorithm to be performed on real-time upon the frames captured by my laptop's camera.

* Algorithm - brief description
The face-swap effect is, in reality, the result of a series of techniques put together to achieve such outcome. I'll briefly discuss each one of them to allow for us to have a better understanding of the produced results.
** Facial landmarks detection
The first step in the face-swapping algorithm is to use a method of facial landmark detection. It is common to do so using the Haars classifiers, which can be promptly done using OpenCV's CascadeClassifier class. However, here I've used the face shape detector provided by the Dlib library. In order to use it, we need a file commonly found under the name of /shape_predictor_68_face_landmarks.dat/, which contains data regarding facial landmarks used to train our detector (which perform regression on this data to be able and find the landmarks on unkown images). In the picture below we can see an example of landmark detection. It is important to note, furthermore, that we don't use all of the points from the landmarks, as our itent is to extract only the contour of the source face (so we can << patch >> it on top of the destination face).

[[./figures/landmarks.png]]

** Finding the "Hull"
After obtaining the landmarks, we proceed to extract the "hull" (i.e.: the contour of the set of facil landmark points), as the points from the interior do not interest us at this second stage. In the previous figure, the hull would be a shape connecting all of the exterior red points, ignoring the interior ones. To calculate the hull of our landmark, we can use OpenCV's convexHull function as shown below:

#+begin_src cpp
  cv::convexHull(element, hull_index, false, false);
#+end_src

In the above snippet, *element* is a set of points representing the detected landmarks and *hull_index* is the index of the landmark points that form the hull (or the contour); the other two parameters simply control the behavior of the method: they tell if the detection is to be performed clockwise (not the case here) and if the latter flag is set to #+begin_src cpp true #+end_src, the hull points (instead of their indexes) are returned.

Once the hull for the destination face is obtained, we proceed to the Delaunay triangulation.

** Delaunay triangulation and affine transformation.

This process seems to be more complex than the previous, but it works in a simple manner: the hull region is subdivided into smaller zones, triangular zones, which allow the faces to be overlap better in the final figure. The smaller triangles inside the hull zone are defined for each to keep a small region of the face, containing one of its key features; this helps warp the source face when "patching" it onto the destination. After performing the triangulation, it is still needed to perform a affine transformation to align the triangles from the source face with those on the destination face. We could, of course, simply toss one on top of the other, but the result wouldn't be as smooth as the one obtained via this kind of transformation.

After finding the Delaunay triangles and performing the affine transformation, we obtain a mask as the one shown in the figure below; this mask, by its turn, is applied to the source image to mix it with the destination image.

[[./figures/mask.png]]

